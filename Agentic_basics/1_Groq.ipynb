{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27287890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f0d3523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m sorry, but I can only answer questions that are related to mathematics. If you have a math question, feel free to ask!"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq()\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an expert in maths and only and only provide the answer to the question related to maths\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is the capital of France?\"\n",
    "      }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_completion_tokens=8192,\n",
    "    top_p=1,\n",
    "    reasoning_effort=\"medium\",\n",
    "    stream=True,\n",
    "    stop=None\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ff7b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "      {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an expert in maths and only and only provide the answer to the question related to maths\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is the capital of France?\"\n",
    "      }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1d3ec9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m sorry, but I can only provide answers to mathematical questions."
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "class ChatGroqWrapper:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model=\"openai/gpt-oss-120b\",\n",
    "        system_prompt=None,\n",
    "        **defaults\n",
    "    ):\n",
    "        self.client = Groq()\n",
    "        self.model = model\n",
    "        self.system_prompt = system_prompt\n",
    "        self.defaults = defaults\n",
    "\n",
    "    def _normalize_messages(self, message):\n",
    "        messages = []\n",
    "\n",
    "        # Inject system prompt once per call\n",
    "        if self.system_prompt:\n",
    "            messages.append({\n",
    "                \"role\": \"system\",\n",
    "                \"content\": self.system_prompt\n",
    "            })\n",
    "\n",
    "        # Case 1: string → user\n",
    "        if isinstance(message, str):\n",
    "            messages.append({\n",
    "                \"role\": \"user\",\n",
    "                \"content\": message\n",
    "            })\n",
    "\n",
    "        # Case 2: dict → default role=user if missing\n",
    "        elif isinstance(message, dict):\n",
    "            messages.append({\n",
    "                \"role\": message.get(\"role\", \"user\"),\n",
    "                \"content\": message[\"content\"]\n",
    "            })\n",
    "\n",
    "        # Case 3: list of messages\n",
    "        elif isinstance(message, list):\n",
    "            for msg in message:\n",
    "                messages.append({\n",
    "                    \"role\": msg.get(\"role\", \"user\"),\n",
    "                    \"content\": msg[\"content\"]\n",
    "                })\n",
    "\n",
    "        else:\n",
    "            raise TypeError(\"Message must be str, dict, or list\")\n",
    "\n",
    "        return messages\n",
    "\n",
    "    def invoke(self, message, stream=False):\n",
    "        messages = self._normalize_messages(message)\n",
    "        return self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            stream=stream,\n",
    "            **self.defaults\n",
    "        )\n",
    "\n",
    "\n",
    "chat = ChatGroqWrapper(\n",
    "    system_prompt=\"You are an expert in maths and only provide mathematical answers.\",\n",
    "    temperature=1,\n",
    "    max_completion_tokens=8192,\n",
    "    top_p=1,\n",
    "    reasoning_effort=\"medium\"\n",
    ")\n",
    "\n",
    "response = chat.invoke(\"What is the capital of France?\", stream=True)\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c28b771d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The quadratic can be factored as a perfect square:\\n\\n\\\\[\\nx^{2}+4x+4 = (x+2)^{2}.\\n\\\\]\\n\\nSetting this equal to zero gives\\n\\n\\\\[\\n(x+2)^{2}=0 \\\\;\\\\Longrightarrow\\\\; x+2 = 0.\\n\\\\]\\n\\nHence the only (double) root is  \\n\\n\\\\[\\n\\\\boxed{x = -2}.\\n\\\\]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat.invoke({\"content\": \"Solve x² + 4x + 4 = 0\"})\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eab2367e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-7ba2e75b-1bd9-4fdc-9c90-cb522d606f16', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\\\\(16\\\\)', role='assistant', annotations=None, executed_tools=None, function_call=None, reasoning='User: \"Now square it\". We previously got 4. Square it => 16. Provide answer.', tool_calls=None))], created=1768212874, model='openai/gpt-oss-120b', object='chat.completion', mcp_list_tools=None, service_tier='on_demand', system_fingerprint='fp_90620edd96', usage=CompletionUsage(completion_tokens=36, prompt_tokens=104, total_tokens=140, completion_time=0.080419383, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=23), prompt_time=0.02772421, prompt_tokens_details=None, queue_time=0.28552973, total_time=0.108143593), usage_breakdown=None, x_groq=XGroq(id='req_01kerv6gkafgsstchwmdks79rq', debug=None, seed=259024629, usage=None))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke([\n",
    "    {\"content\": \"2 + 2\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"4\"},\n",
    "    {\"content\": \"Now square it\"}\n",
    "])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
